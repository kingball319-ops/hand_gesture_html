<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>AI Hand Tracker Debug</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<style>
  body { margin:0; overflow:hidden; background:black; font-family: sans-serif; }
  video { display:none; }
  #status {
    position: fixed; top: 10px; left: 10px; color: #00ff00; 
    background: rgba(0,0,0,0.7); padding: 10px; border-radius: 5px; z-index: 20; font-size: 12px;
  }
  #overlay {
    position: fixed; top: 0; left: 0; width: 100%; height: 100%;
    background: rgba(0,0,0,0.8); display: flex; flex-direction: column;
    justify-content: center; align-items: center; z-index: 30; color: white;
  }
  button { padding: 15px 30px; font-size: 18px; cursor: pointer; background: #cc66ff; border: none; border-radius: 50px; color: white; }
</style>
</head>
<body>

<div id="status">Status: Waiting for User...</div>

<div id="overlay">
  <h2>AI Particle System</h2>
  <p>Place hand 2-3 feet away from camera</p>
  <button id="startButton">START EXPERIENCE</button>
</div>

<video id="video" autoplay playsinline></video>

<script src="https://cdn.jsdelivr.net/npm/three@0.158/build/three.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.min.js"></script>

<script>
const statusDiv = document.getElementById('status');
const videoElement = document.getElementById('video');

// 1. THREE.js Setup (Shortened for brevity)
const scene = new THREE.Scene();
const camera = new THREE.PerspectiveCamera(70, innerWidth/innerHeight, 0.1, 500);
camera.position.z = 65;
const renderer = new THREE.WebGLRenderer({ antialias:false });
renderer.setSize(innerWidth, innerHeight);
document.body.appendChild(renderer.domElement);

const geometry = new THREE.BufferGeometry();
const count = 5000;
const pos = new Float32Array(count * 3);
for(let i=0; i<count*3; i++) pos[i] = (Math.random()-0.5)*50;
geometry.setAttribute('position', new THREE.BufferAttribute(pos, 3));
const particles = new THREE.Points(geometry, new THREE.PointsMaterial({size:0.5, color: 0xcc66ff}));
scene.add(particles);

// 2. MediaPipe Hands Setup
const hands = new Hands({
  locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
});

hands.setOptions({ maxNumHands: 1, modelComplexity: 1, minDetectionConfidence: 0.5, minTrackingConfidence: 0.5 });

hands.onResults((results) => {
  if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
    statusDiv.innerText = "Status: Hand Detected! Move it!";
    const hand = results.multiHandLandmarks[0];
    // Index finger tip (Landmark 8) se particles rotate karein
    particles.rotation.y = hand[8].x * 5;
    particles.rotation.x = hand[8].y * 5;
  } else {
    statusDiv.innerText = "Status: Searching for Hand...";
  }
});

// 3. Start Logic
document.getElementById('startButton').addEventListener('click', async () => {
  document.getElementById('overlay').style.display = 'none';
  statusDiv.innerText = "Status: Loading AI Models...";
  
  const cameraUtils = new Camera(videoElement, {
    onFrame: async () => {
      await hands.send({image: videoElement});
    },
    width: 640, height: 480
  });

  cameraUtils.start().then(() => {
    statusDiv.innerText = "Status: Camera On. Loading Hand Model...";
  }).catch(err => {
    statusDiv.innerText = "Status: Camera Error: " + err;
  });

  function animate() {
    requestAnimationFrame(animate);
    renderer.render(scene, camera);
  }
  animate();
});
</script>
</body>
</html>
